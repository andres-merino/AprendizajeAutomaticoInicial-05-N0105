\documentclass[a4,11pt]{aleph-notas}
% Se puede ver la documentación aquí: 
% https://github.com/alephsub0/LaTeX_aleph-notas

% -- Paquetes adicionales 
\usepackage{enumitem}
\usepackage{url}
\usepackage{array}
\usepackage{booktabs}
\usepackage{longtable}
\usepackage{environ}  % Para definir nuevos entornos
\hypersetup{
    urlcolor=blue,
    linkcolor=blue,
}

% Definición del nuevo ambiente
\NewEnviron{materiales}{%
    \begin{minipage}{12cm}
        \vspace{0.1mm}
        \begin{itemize}[leftmargin=*]
            \BODY % Contenido de la lista
        \end{itemize}
        \vspace{1mm}
    \end{minipage}
}


% -- Datos 
\institucion{Escuela de Ciencias Físicas y Matemática}
\carrera{Ciencia de Datos}
\asignatura{Aprendizaje Automático Inicial}
\tema{Clase 03: Conjuntos de Entrenamiento y Validación}
\autor{Andrés Merino}
\fecha{Semestre 2025-1}

\logouno[0.14\textwidth]{Logos/logoPUCE_04_ac}
\definecolor{colortext}{HTML}{0030A1}
\definecolor{colordef}{HTML}{0030A1}
\fuente{montserrat}


% -- Comandos para tablas
\input{aleph-codigo}

\begin{document}

\encabezado


\section*{Resultado de Aprendizaje}

\subsection*{RdA de la asignatura:}
\begin{itemize}
    \item \textbf{RdA 1:} 
    Plantear los conceptos fundamentales del aprendizaje automático, incluyendo los principios básicos, técnicas de preprocesado de datos, métodos de evaluación y ajuste de modelos, destacando su importancia en el análisis y resolución de problemas de datos.
\end{itemize}

\subsection*{RdA de la actividad:}
\begin{itemize}
    \item Comprender las técnicas principales de preprocesado de datos, como limpieza, normalización, discretización y reducción de dimensionalidad.
    \item Aplicar métodos de partición de conjuntos de datos, como leave-one-out, leave-p-out y k-fold cross-validation.
    \item Identificar la importancia de los conjuntos de validación en el proceso de ajuste y evaluación de modelos.
\end{itemize}

\section*{Introducción}

\paragraph{Pregunta inicial:} 
¿Cómo podemos asegurar que nuestro modelo generalice bien y no simplemente memorice los datos?


\section*{Desarrollo}

\subsection*{Actividad 1: Preprocesado de Datos (30 minutos)}  

En esta actividad, los estudiantes aprenderán las técnicas básicas de preprocesado de datos, incluyendo limpieza, normalización, discretización y reducción de dimensionalidad. Estas técnicas son fundamentales para preparar los datos para modelos de aprendizaje automático, asegurando su calidad y optimizando su representación.


\paragraph{Recursos:} 
\begin{itemize}
    \item Presentación teórica sobre preprocesado de datos.
    \item Jupyter Notebook con ejemplos de preprocesado utilizando \texttt{scikit-learn}.
    \item Conjunto de datos Iris (disponible en \texttt{scikit-learn}).
\end{itemize}

\paragraph{Ejercicio práctico:} \hspace{0pt}

\begin{pycodigo}
\begin{lstlisting}[language=Python]
import pandas as pd
from sklearn.datasets import load_iris
from sklearn.preprocessing import StandardScaler, KBinsDiscretizer
from sklearn.decomposition import PCA

# Cargar datos
data = load_iris()
X, y = data.data, data.target

# Normalización
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Discretización
discretizer = KBinsDiscretizer(n_bins=3, encode='ordinal', strategy='uniform')
X_discretized = discretizer.fit_transform(X_scaled)

# Reducción de dimensionalidad
pca = PCA(n_components=2)
X_reduced = pca.fit_transform(X_discretized)

print("Datos preprocesados:")
print(X_reduced[:5])
\end{lstlisting}
\end{pycodigo}

\paragraph{Verificación de aprendizaje:} Con un conjunto de datos con al menos 5 características numéricas y 1 categórica (puede ser proporcionado o descargado de una fuente como \texttt{Kaggle} o \texttt{UCI Machine Learning Repository}). Deben realizar las siguientes tareas:
\begin{enumerate}
    \item Identificar valores faltantes, valores atípicos y datos redundantes, y proponer una estrategia para manejarlos.
    \item Estandarizar las variables numéricas y codificar las categóricas (por ejemplo, con \texttt{One-Hot Encoding} o \texttt{Label Encoding}).
    \item Aplicar reducción de dimensionalidad utilizando \texttt{PCA} o seleccionando un subconjunto de características basado en correlaciones.
\end{enumerate}

\subsection*{Actividad 2: Conjuntos de Entrenamiento y Test (40 minutos)}  

En esta actividad, se abordará la importancia de dividir un conjunto de datos en entrenamiento, prueba y validación. Se explicarán los métodos más comunes: \texttt{train\_test\_split}, k-fold cross-validation, leave-one-out y leave-p-out.

\paragraph{¿Cómo lo haremos?}  
\begin{itemize}[leftmargin=*]
    \item \textbf{Exploración del cuaderno de Jupyter:}  
    Se proporcionarán ejemplos prácticos de cómo dividir conjuntos de datos en entrenamiento, prueba y validación utilizando diferentes estrategias.
    \begin{quote}
        Enlace al cuaderno: \href{https://colab.research.google.com/github/andres-merino/AprendizajeAutomaticoInicial-05-N0105/blob/main/2-Notebooks/03-Conjuntos-Entrenamiento-Prueba.ipynb}{03-Conjuntos-Entrenamiento-Prueba}.
    \end{quote}
\end{itemize}

\paragraph{Ejercicio práctico:}  \hspace{0pt}

\begin{pycodigo}
\begin{lstlisting}[language=Python]
from sklearn.model_selection import train_test_split, KFold, cross_val_score
from sklearn.ensemble import RandomForestClassifier

# Dividir datos en entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X_reduced, y, test_size=0.2, random_state=42)

# Validación cruzada
kfold = KFold(n_splits=5, shuffle=True, random_state=42)
model = RandomForestClassifier()
scores = cross_val_score(model, X_train, y_train, cv=kfold)

print("Scores de validación cruzada:", scores)
print("Promedio de scores:", scores.mean())
\end{lstlisting}
\end{pycodigo}


\paragraph{Verificación de aprendizaje:} Con un conjunto de datos  (por ejemplo, el conjunto \textit{Titanic}), realice las siguientes actividades:
\begin{enumerate}
    \item Implementar al menos tres métodos de partición:
    \begin{itemize}
        \item División simple (\texttt{train\_test\_split}).
        \item Validación cruzada estratificada.
        \item k-fold cross-validation (sin entrenar modelos).
    \end{itemize}
    \item Dividir el conjunto de datos utilizando cada método y observar las proporciones de clases en cada subconjunto.
\end{enumerate}



\section*{Cierre}

\paragraph{Tarea:} Aplicar todo lo aprendido en un conjunto nuevo de datos.
    
\paragraph{Pregunta de investigación:} 
\begin{enumerate}
    \item ¿Qué estrategias existen para manejar conjuntos de datos desbalanceados al realizar particiones de entrenamiento y prueba?
    \item ¿Cómo afecta el tamaño relativo de los conjuntos de entrenamiento y prueba al desempeño de un modelo?
    \item ¿Qué tipos de problemas se pueden enfrentar al evaluar modelos con conjuntos de datos extremadamente pequeños? ¿Cómo puede abordarse este desafío?
\end{enumerate}
    


\end{document} 